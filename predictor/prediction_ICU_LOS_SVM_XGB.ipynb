{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d14c0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import seaborn as sns\n",
    "from pandas import DataFrame, Series\n",
    "import scipy.stats as scst\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, mean_squared_error, r2_score\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import OneClassSVM, SVC\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "import time\n",
    "import xgboost as xgb\n",
    "\n",
    "from encode_many import encode_many\n",
    "from scale_it import scale_it\n",
    "from unscale import unscale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d146920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "# path = 'string'\n",
    "path = 'final_patient_data.xlsx'\n",
    "PPdata = pd.read_excel(r'/Users/fardadddii/Documents/Hospital data/code/final_patient_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6203f1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##cleaning\n",
    "# checking number of NANs\n",
    "PPdata.isna().sum()\n",
    "# filling NANs\n",
    "PPdata['SOURCE_OF_ADMISSION'].fillna(0, inplace = True)\n",
    "# drop with thresshol\n",
    "PPdata.dropna(thresh=2)\n",
    "#duplicate data\n",
    "PPdata.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44073ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#meaningless mis-recorded dat\n",
    "ADI_neg_droped_index = PPdata[PPdata['ADMISSION_TO_DEATH_INTERVAL']<0].index\n",
    "PPdata.drop(index = PPdata[PPdata['ADMISSION_TO_DEATH_INTERVAL']<0].index, inplace =True)\n",
    "PPdata = PPdata.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e19cfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial visualization of Race distribusion (other features could be passed)\n",
    "feat = 'RACE'\n",
    "g = sns.countplot(PPdata[feat], color = 'seagreen')\n",
    "# g.set_xticklabels(['White','Black', 'Other', 'Asian', 'Hispanic'])\n",
    "#g.set_xticklabels(['White','Black', 'Hispanic'])\n",
    "for p in g.patches:\n",
    "    g.annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.15, p.get_height()+100))\n",
    "plt.title('Distribution of patient: '+feat)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe1c9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hot Encoding\n",
    "\n",
    "PPdata = PPdata.join(encode_many(PPdata,'RACE'))   \n",
    "PPdata = PPdata.join(encode_many(PPdata,'AGE'))   \n",
    "PPdata = PPdata.join(encode_many(PPdata,'MEDICARE_STATUS_CODE'))   \n",
    "PPdata = PPdata.join(encode_many(PPdata,'TYPE_OF_ADMISSION'))   \n",
    "PPdata = PPdata.join(encode_many(PPdata,'SOURCE_OF_ADMISSION'))   \n",
    "\n",
    "##Binary Encoding\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(PPdata['DISCHARGE_STATUS'])\n",
    "PPdata['DISCHARGE_STATUS_BINARY'] = (le.transform(PPdata['DISCHARGE_STATUS']))\n",
    "\n",
    "# Sex Encoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(PPdata['SEX'])\n",
    "PPdata['SEX_BINARY'] = (le.transform(PPdata['SEX']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d8eb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final SVM tuning with nested cross validation and feature importance\n",
    "# This in-house code is faster than GridSearchCV. We have a grid search tuning at the end of this code\n",
    "\n",
    "data = PPdata[['CCI','Race1', 'Race2', 'Race3', 'Race4',\n",
    "       'Race5', 'SEX_BINARY', 'Age1', 'Age2', 'Age3', 'Age4', 'Age5', 'Age6',\n",
    "       'Age7', 'Age8', 'medicale_status_code1',\n",
    "       'medicale_status_code2', 'medicale_status_code3',\n",
    "       'medicale_status_code4', 'medicale_status_code5', 'type_of_admission1',\n",
    "       'type_of_admission2', 'type_of_admission3', 'type_of_admission4']].copy()\n",
    "\n",
    "#data = PPdata[['CCI_POA','Race1', 'Race2', 'Race3', 'Race4',\n",
    "#      'Race5']].copy()\n",
    "\n",
    "label = PPdata[['ICU']].copy()\n",
    "\n",
    "# scaler\n",
    "\n",
    "#_, min_icu, max_icu = scale_it(label,'ICU')\n",
    "\n",
    "_, min_cci, max_cci  = scale_it(data,'CCI_POA')\n",
    "\n",
    "## function for unscalaing\n",
    "\n",
    "x_data = data.to_numpy()\n",
    "\n",
    "y_data = label.to_numpy()\n",
    "\n",
    "cv_in = 5\n",
    "cv_out = 10\n",
    "rand = 1\n",
    "\n",
    "kernel_rng = ['poly', 'rbf', 'sigmoid']\n",
    "gamma_rng = ['scale', 'auto']\n",
    "degree_rng = [2,3,4,5]\n",
    "C_rng = [0.1, 1, 5, 10, 20]\n",
    "#C_rng = [0.001,1]\n",
    "\n",
    "indexer = 0\n",
    "indexer_out = 0\n",
    "elapsed = 0\n",
    "\n",
    "cv_inner = KFold(n_splits=cv_in, shuffle=True, random_state=42)\n",
    "cv_outer = KFold(n_splits=cv_out, shuffle=True, random_state=42)\n",
    "\n",
    "outer_results = pd.DataFrame(columns = ['outer_fold', 'kernel', 'degree', 'C_reg','gamma', 'mae_test', 'mae_train'])\n",
    "\n",
    "fi_mx = []\n",
    "fi_feat = []\n",
    "fi_comined = []\n",
    "t = time.time()\n",
    "\n",
    "for cv_ind_outer, (train_out, test_out) in enumerate(cv_outer.split(x_data,y_data)):\n",
    "    \n",
    "    optimization_folds = pd.DataFrame(columns = ['inner_Fold', 'kernel', 'degree', 'C_reg','gamma', 'mae_test'])\n",
    "    \n",
    "    x_train_out = x_data[train_out]\n",
    "    y_train_out = y_data[train_out]\n",
    "    \n",
    "    x_test_out = x_data[test_out]\n",
    "    y_test_out = y_data[test_out]\n",
    "    \n",
    "    for cv_ind_inner, (train_in, test_in) in enumerate(cv_inner.split(x_train_out,y_train_out)):\n",
    "        \n",
    "        optimization_par = pd.DataFrame(columns = ['inner_Fold', 'kernel', 'degree', 'C_reg','gamma', 'mae_test'])\n",
    "        \n",
    "        print(f'inner fold number  {cv_ind_inner}')\n",
    "        \n",
    "        t = time.time()\n",
    "        \n",
    "        x_train_in = x_train_out[train_in]\n",
    "        y_train_in = y_train_out[train_in]\n",
    "        \n",
    "        x_test_in = x_train_out[test_in]\n",
    "        y_test_in = y_train_out[test_in]\n",
    "                           \n",
    "        for kr_ind, krn in enumerate(kernel_rng):\n",
    "\n",
    "            for deg in degree_rng:\n",
    "\n",
    "                for Cr in C_rng:\n",
    "\n",
    "                    for gm_ind,gam in enumerate(gamma_rng):\n",
    "\n",
    "                        mlp = SVR(C=Cr, kernel=krn, degree=deg, gamma=gam)\n",
    "\n",
    "                        mlp.fit(x_train_in, y_train_in)\n",
    "\n",
    "                        y_pred_in = mlp.predict(x_test_in)\n",
    "                        #score = mlp.score(x_test_in,y_test_in)\n",
    "\n",
    "                        y_test_in_unscaled = unscale(y_test_in)\n",
    "                        y_pred_in_unscaled = unscale(y_pred_in)\n",
    "                        \n",
    "                        \n",
    "                        perf_unscaled = mae(y_test_in_unscaled,y_pred_in_unscaled)\n",
    "                        perf = mae(y_test_in,y_pred_in)\n",
    "                        \n",
    "                        \n",
    "                        print(perf)\n",
    "\n",
    "                        optimization_par.loc[indexer,:] = [cv_ind_inner, kr_ind, deg, Cr, gm_ind, perf]\n",
    "\n",
    "                        indexer+=1\n",
    "\n",
    "        min_optimized = optimization_par[optimization_par['mae_test'] == np.min(optimization_par['mae_test'])]\n",
    "\n",
    "        optimization_folds = optimization_folds.append(min_optimized, ignore_index=True)\n",
    "\n",
    "    print(f'outer_fold number {cv_ind_outer}')\n",
    "    \n",
    "    print(f'inner folds optimized values \\n \\n {optimization_folds}')\n",
    "    \n",
    "    modes = optimization_folds['kernel'].mode()\n",
    "    temp = []\n",
    "    for m in modes:\n",
    "        temp.append(optimization_folds[optimization_folds['kernel']==m]['mae_test'].min())\n",
    "    kr_op = modes[np.where(np.array(temp)==np.array(temp).min())[0][0]]\n",
    "   \n",
    "    modes = optimization_folds['degree'].mode()\n",
    "    temp = []\n",
    "    for m in modes:\n",
    "        temp.append(optimization_folds[optimization_folds['degree']==m]['mae_test'].min())\n",
    "    deg_op = modes[np.where(np.array(temp)==np.array(temp).min())[0][0]]\n",
    "   \n",
    "    modes = optimization_folds['C_reg'].mode()\n",
    "    temp = []\n",
    "    for m in modes:\n",
    "        temp.append(optimization_folds[optimization_folds['C_reg']==m]['mae_test'].min())\n",
    "    Cr_op = modes[np.where(np.array(temp)==np.array(temp).min())[0][0]]\n",
    "    \n",
    "    modes = optimization_folds['gamma'].mode()\n",
    "    temp = []\n",
    "    for m in modes:\n",
    "        temp.append(optimization_folds[optimization_folds['gamma']==m]['mae_test'].min())\n",
    "    gamma_op = modes[np.where(np.array(temp)==np.array(temp).min())[0][0]]\n",
    "    \n",
    "    mlp1 = SVR(C=Cr_op, kernel=kernel_rng[kr_op], degree=deg_op, gamma=gamma_rng[gamma_op])\n",
    "    \n",
    "    mlp1.fit(x_train_out, y_train_out)\n",
    "    \n",
    "    ypred_test_out = mlp1.predict(x_test_out)\n",
    "    ypred_test_out_unscaled = unscale(ypred_test_out)\n",
    "    \n",
    "    \n",
    "    ypred_train_out = mlp1.predict(x_train_out)\n",
    "    ypred_train_out_unscaled = unscale(ypred_train_out)\n",
    "    \n",
    "    y_train_out_unscaled = unscale(y_train_out)\n",
    "    y_test_out_unscaled = unscale(y_test_out)\n",
    "    \n",
    "    mae_train_out_unscaled = mae (y_train_out_unscaled, ypred_train_out_unscaled)\n",
    "    \n",
    "    mae_test_out_unscaled = mae (y_test_out_unscaled, ypred_test_out_unscaled)\n",
    "    \n",
    "    mae_train_out = mae (y_train_out, ypred_train_out)\n",
    "    \n",
    "    mae_test_out = mae (y_test_out, ypred_test_out)\n",
    "    \n",
    "    print(mae_test_out)\n",
    "    \n",
    "    outer_results.loc[indexer_out,:] = [cv_ind_outer, kernel_rng[kr_op], deg_op, Cr_op, gamma_rng[gamma_op],mae_test_out, mae_train_out]\n",
    "    indexer_out+=1\n",
    "\n",
    "    elapsed = time.time() - t\n",
    "\n",
    "    time_estimate = elapsed*(10 - cv_ind_outer)\n",
    "\n",
    "    print(f'remaining time is {time_estimate/60} minutes')\n",
    "\n",
    "    print (f'omtimized values are \\n \\n {outer_results}')\n",
    "\n",
    "optimization_par  # the whole parameter variation dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbfb1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##XGBOOSt # grid search tuning with nested cross validation####\n",
    "\n",
    "data = PPdata[['RACE', 'CCI', 'SEX', 'AGE', 'TYPE_OF_ADMISSION', 'MEDICARE_STATUS_CODE']]\n",
    "\n",
    "lable = PPdata['ICU']\n",
    "\n",
    "# x_data = PPdata[['CCI_POA','RACE']].copy()\n",
    "\n",
    "# y_data = PPdata[['ICU']].copy()\n",
    "\n",
    "#_, min_icu, max_icu = scale_it(label,'ICU')\n",
    "\n",
    "_, min_cci, max_cci  = scale_it(x_data,'CCI_POA')\n",
    "\n",
    "## function for unscalaing\n",
    "\n",
    "data = x_data\n",
    "label = y_data\n",
    "\n",
    "eval_metric_name = 'mae'\n",
    "\n",
    "#del optimization_par\n",
    "\n",
    "optimization_par = pd.DataFrame(columns = ['Fold', 'depth', 'gamma', 'eta', 'min_child_weight','subsample','objective', 'min_eval', 'mae_test', 'mae_train'])\n",
    "\n",
    "optimization_folds = pd.DataFrame(columns = ['Fold', 'depth', 'gamma', 'eta', 'min_child_weight','subsample','objective', 'min_eval', 'mae_test', 'mae_train'])\n",
    "\n",
    "objective_funcs = ['reg:squarederror', 'reg:squaredlogerror', 'reg:pseudohubererror']\n",
    "\n",
    "learning_rate = [0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.5]\n",
    "\n",
    "three_depth = range(2,16)\n",
    "\n",
    "#gamme_value = np.linspace(0,10,2, endpoint = True)\n",
    "gamme_value = [0, 5, 10]\n",
    "\n",
    "subsample_values = [0.3, 0.5, 0.9]\n",
    "\n",
    "min_child_weight = [1, 5, 10]\n",
    "indexer = 0\n",
    "indexer_out = 0\n",
    "elapsed = 0\n",
    "\n",
    "cv_outer = KFold(n_splits = 10, shuffle=True, random_state=42)\n",
    "cv_in = KFold(n_splits = 5, shuffle=True, random_state=42)\n",
    "\n",
    "#optimization_folds = []\n",
    "\n",
    "outer_results = pd.DataFrame(columns = ['OuterFold', 'depth', 'gamma', 'eta', 'min_child_weight','subsample','objective', 'min_eval_outer', 'mae_test_outer', 'mae_train_outer'])\n",
    "\n",
    "fi_mx = []\n",
    "fi_feat = []\n",
    "fi_comined = []\n",
    "\n",
    "param = {}\n",
    "\n",
    "for cv_ind_inner, (train_in, test_in) in enumerate(cv_in.split(data, lable)):\n",
    "\n",
    "    print(f'inner fold number  {cv_ind_inner}')\n",
    "\n",
    "    t = time.time()\n",
    "\n",
    "    X_train_in = data.iloc[train_in]\n",
    "    y_train_in = lable.iloc[train_in]\n",
    "\n",
    "    X_test_in = data.iloc[test_in]\n",
    "    y_test_in = lable.iloc[test_in]\n",
    "\n",
    "    dtest_in = xgb.DMatrix(X_test_in, label=y_test_in)\n",
    "    dtrain_in = xgb.DMatrix(X_train_in, label=y_train_in)\n",
    "    optimization_par = pd.DataFrame(columns = ['Fold', 'depth', 'gamma', 'eta', 'min_child_weight','subsample','objective', 'min_eval', 'mae_test', 'mae_train'])\n",
    "\n",
    "    for dp_id, max_depth_input in enumerate(three_depth):\n",
    "\n",
    "        print(f'depth is {max_depth_input}')\n",
    "\n",
    "        for gamma_val in gamme_value:\n",
    "\n",
    "            for eta_val in learning_rate:\n",
    "\n",
    "                for reg_ind, reg in enumerate(objective_funcs):\n",
    "\n",
    "                    for subs in subsample_values:\n",
    "\n",
    "                        for ch_w in min_child_weight:\n",
    "\n",
    "                            param = {'max_depth': max_depth_input, 'objective': reg, 'eval_metric' : eval_metric_name}\n",
    "                            param['nthread'] = 4\n",
    "                            #param['eval_metric'] = 'auc'\n",
    "                            param['booster'] = 'gbtree'\n",
    "                            param['validate_parameters'] = True\n",
    "                            param['gamma'] = gamma_val\n",
    "                            param['eta'] = eta_val   \n",
    "\n",
    "                            param['subsample'] = subs\n",
    "\n",
    "                            param['min_child_weight'] = ch_w\n",
    "\n",
    "                            evallist = [(dtest_in, 'eval'), (dtrain_in, 'train')]\n",
    "\n",
    "                            num_round = 1000\n",
    "\n",
    "                            np.array\n",
    "\n",
    "                            evals_result = {}\n",
    "                            bst = xgb.train(param, dtrain_in, num_round, verbose_eval = False, evals=evallist, early_stopping_rounds=10, evals_result=evals_result)\n",
    "\n",
    "                            ypred_test_in = bst.predict(dtest_in)\n",
    "                            y_test_in\n",
    "\n",
    "                            ypred_train_in = bst.predict(dtrain_in)\n",
    "                            y_train_in\n",
    "\n",
    "                            mae_train = mean_absolute_error (y_train_in, ypred_train_in)\n",
    "\n",
    "                            mae_test = mean_absolute_error (y_test_in, ypred_test_in)\n",
    "                            \n",
    "                            print(mae_test)\n",
    "\n",
    "                            min_eval_inner = np.min(evals_result['eval'][eval_metric_name])\n",
    "\n",
    "                            optimization_par.loc[indexer,:] = [cv_ind_inner, max_depth_input, gamma_val, eta_val, ch_w, subs, reg_ind, min_eval_inner, mae_test, mae_train]\n",
    "\n",
    "                            indexer+=1\n",
    "\n",
    "    min_optimized = optimization_par[optimization_par['mae_test'] == np.min(optimization_par['mae_test'])]\n",
    "\n",
    "    optimization_folds = optimization_folds.append(min_optimized, ignore_index=True)\n",
    "    fi_score = bst.get_score (importance_type = 'cover')\n",
    "    \n",
    "    fi_comined.append(fi_score)\n",
    "\n",
    "    fi_mx.append(list(fi_score.values()))\n",
    "\n",
    "    fi_feat.append(list(fi_score.keys()))\n",
    "    \n",
    "print(optimization_folds)\n",
    "\n",
    "feature_importance = DataFrame(fi_mx, columns = fi_feat[0])\n",
    "\n",
    "feature_importance_ms = DataFrame(np.array([list(feature_importance.mean()), list(feature_importance.std())]), index = ['mean', 'std'], columns = fi_feat[0]).T\n",
    "feature_importance_ms.sort_values(by=['mean'], ascending = True, inplace = True)\n",
    "\n",
    "font = {'family' : 'arial',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 15}\n",
    "mpl.rc('font', **font)\n",
    "plt.barh(list(feature_importance_ms.index),list(feature_importance_ms['mean']) ,  xerr = list(feature_importance_ms['std']), color = 'g')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b6a891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# permutation based feature importance\n",
    "\n",
    "X = data\n",
    "\n",
    "#_, min_cci, max_cci  = scale_it(X,'CCI')\n",
    "\n",
    "r = r_multi['neg_mean_absolute_error']\n",
    "\n",
    "CCI_imp = abs(r.importances[0])\n",
    "\n",
    "sex_imp = abs(r.importances[6])\n",
    "\n",
    "race_imp = sum(abs(r.importances[1:5]))\n",
    "\n",
    "age_imp = sum(abs(r.importances[7:14]))\n",
    "\n",
    "medicare_imp = sum(abs(r.importances[15:19]))\n",
    "\n",
    "type_imp = sum(abs(r.importances[20:23]))\n",
    "\n",
    "columns_imp = ['CCI', 'Sex', 'Race', 'Age', 'Medicare OREC', 'Type of admission']\n",
    "\n",
    "var_mean = [CCI_imp.mean(), sex_imp.mean(), race_imp.mean(), age_imp.mean(), medicare_imp.mean(), type_imp.mean()]\n",
    "\n",
    "feature_importances = DataFrame(var_mean, index = columns_imp)\n",
    "\n",
    "feature_importances_sorted = feature_importances.sort_values(by = 0, ascending = True)\n",
    "\n",
    "font = {'family' : 'arial',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 15}\n",
    "mpl.rc('font', **font)\n",
    "\n",
    "plt.barh( list(feature_importances_sorted.index), list(feature_importances_sorted[0]), color = 'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbfe265",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Working Regression XGBOOSt # optimization with nested cross validation####\n",
    "\n",
    "data = PPdata[['RACE', 'CCI', 'SEX', 'AGE', 'TYPE_OF_ADMISSION', 'MEDICARE_STATUS_CODE']]\n",
    "\n",
    "lable = PPdata['ICU']\n",
    "\n",
    "eval_metric_name = 'mae'\n",
    "\n",
    "optimization_par = pd.DataFrame(columns = ['Fold', 'depth', 'gamma', 'eta', 'min_child_weight','subsample','objective', 'min_eval', 'mae_test', 'mae_train'])\n",
    "\n",
    "optimization_folds = pd.DataFrame(columns = ['Fold', 'depth', 'gamma', 'eta', 'min_child_weight','subsample','objective', 'min_eval', 'mae_test', 'mae_train'])\n",
    "\n",
    "objective_funcs = ['reg:squarederror', 'reg:squaredlogerror', 'reg:pseudohubererror']\n",
    "#objective_funcs = ['reg:squarederror']\n",
    "\n",
    "learning_rate = [0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.5]\n",
    "\n",
    "three_depth = range(6,7)\n",
    "#three_depth = [6]\n",
    "\n",
    "gamme_value = np.linspace(0,10,2, endpoint = True)\n",
    "#gamme_value = [0, 5, 10]\n",
    "\n",
    "subsample_values = [0.3, 0.5, 0.9]\n",
    "\n",
    "min_child_weight = [1, 5, 10]\n",
    "\n",
    "\n",
    "indexer = 0\n",
    "indexer_out = 0\n",
    "elapsed = 0\n",
    "\n",
    "cv_outer = KFold(n_splits = 10, shuffle=True, random_state=42)\n",
    "cv_in = KFold(n_splits = 5, shuffle=True, random_state=42)\n",
    "\n",
    "outer_results = pd.DataFrame(columns = ['OuterFold', 'depth', 'gamma', 'eta', 'min_child_weight','subsample','objective', 'min_eval_outer', 'mae_test_outer', 'mae_train_outer'])\n",
    "\n",
    "fi_mx = []\n",
    "fi_feat = []\n",
    "fi_comined = []\n",
    "\n",
    "for cv_ind_outer, (train_out, test_out) in enumerate(cv_outer.split(data, lable)):\n",
    "    \n",
    "    X_train_out = data.iloc[train_out]\n",
    "    y_train_out = lable.iloc[train_out]\n",
    "    \n",
    "    X_test_out = data.iloc[test_out]\n",
    "    y_test_out = lable.iloc[test_out]\n",
    "    \n",
    "    dtest_out = xgb.DMatrix(X_test_out, label=y_test_out)\n",
    "    dtrain_out = xgb.DMatrix(X_train_out, label=y_train_out)\n",
    "    \n",
    "    param = {}\n",
    "    \n",
    "    for cv_ind_inner, (train_in, test_in) in enumerate(cv_in.split(X_train_out, y_train_out)):\n",
    "        \n",
    "        print(f'inner fold number  {cv_ind_inner}')\n",
    "        \n",
    "        t = time.time()\n",
    "        \n",
    "        X_train_in = data.iloc[train_in]\n",
    "        y_train_in = lable.iloc[train_in]\n",
    "        \n",
    "        X_test_in = data.iloc[test_in]\n",
    "        y_test_in = lable.iloc[test_in]\n",
    "        \n",
    "        dtest_in = xgb.DMatrix(X_test_in, label=y_test_in)\n",
    "        dtrain_in = xgb.DMatrix(X_train_in, label=y_train_in)\n",
    "        \n",
    "        for dp_id, max_depth_input in enumerate(three_depth):\n",
    "            \n",
    "            print(f'depth is {max_depth_input}')\n",
    "            \n",
    "            for gamma_val in gamme_value:\n",
    "\n",
    "                for eta_val in learning_rate:\n",
    "\n",
    "                    for reg_ind, reg in enumerate(objective_funcs):\n",
    "                        \n",
    "                        for subs in subsample_values:\n",
    "                            \n",
    "                            for ch_w in min_child_weight:\n",
    "\n",
    "                                param = {'max_depth': max_depth_input, 'objective': reg, 'eval_metric' : eval_metric_name}\n",
    "                                param['nthread'] = 4\n",
    "                                param['booster'] = 'gbtree'\n",
    "                                param['validate_parameters'] = True\n",
    "                                param['gamma'] = gamma_val\n",
    "                                param['eta'] = eta_val \n",
    "\n",
    "                                param['subsample'] = subs \n",
    "\n",
    "                                param['min_child_weight'] = ch_w \n",
    "\n",
    "                                evallist = [(dtest_in, 'eval'), (dtrain_in, 'train')]\n",
    "\n",
    "                                num_round = 1000\n",
    "\n",
    "                                np.array\n",
    "\n",
    "                                evals_result = {}\n",
    "                                bst = xgb.train(param, dtrain_in, num_round, verbose_eval = False, evals=evallist, early_stopping_rounds=10, evals_result=evals_result)\n",
    "\n",
    "                                ypred_test_in = bst.predict(dtest_in)\n",
    "                                y_test_in\n",
    "\n",
    "                                ypred_train_in = bst.predict(dtrain_in)\n",
    "                                y_train_in\n",
    "\n",
    "                                mae_train = mean_absolute_error (y_train_in, ypred_train_in)\n",
    "\n",
    "                                mae_test = mean_absolute_error (y_test_in, ypred_test_in)\n",
    "\n",
    "                                min_eval_inner = np.min(evals_result['eval'][eval_metric_name])\n",
    "\n",
    "                                optimization_par.loc[indexer,:] = [cv_ind_inner, max_depth_input, gamma_val, eta_val, ch_w, subs, reg_ind, min_eval_inner, mae_test, mae_train]\n",
    "\n",
    "                                indexer+=1\n",
    "\n",
    "        min_optimized = optimization_par[optimization_par['mae_test'] == np.min(optimization_par['mae_test'])]\n",
    "\n",
    "        optimization_folds = optimization_folds.append(min_optimized, ignore_index=True)\n",
    "\n",
    "    elapsed = time.time() - t\n",
    "\n",
    "    time_estimate = elapsed*(10 - cv_ind_outer)\n",
    "\n",
    "    print(f'remaining time is {time_estimate/60} minutes')\n",
    "\n",
    "    print(f'outer_fold number {cv_ind_outer}')\n",
    "    \n",
    "    print(f'optimized values \\n {min_optimized}')\n",
    "    \n",
    "    max_depth_input_op = int(round(optimization_folds['depth'].mean()))\n",
    "    \n",
    "    eta_val_op = float(optimization_folds.loc[-4:,['eta']].mean())\n",
    "    \n",
    "    gamma_val_op = int(optimization_folds.loc[-4:,['gamma']].mean())\n",
    "        \n",
    "    sub_op = float(optimization_folds.loc[-4:,['subsample']].mean())\n",
    "        \n",
    "    mc_w_op = int(round(optimization_folds.loc[-4:,['min_child_weight']].mean()))\n",
    "\n",
    "    param = {'max_depth': max_depth_input_op, 'objective': reg, 'eval_metric' : eval_metric_name}\n",
    "\n",
    "    param['gamma'] = gamma_val_op\n",
    "\n",
    "    param['eta'] = eta_val_op\n",
    "    \n",
    "    param['subsample']  = sub_op\n",
    "    \n",
    "    param['min_child_weight'] = mc_w_op\n",
    "    \n",
    "    evallist_out = [(dtest_out, 'eval'), (dtrain_out, 'train')]\n",
    "    \n",
    "    eval_results_out = {}\n",
    "\n",
    "    bst1 = xgb.train(param, dtrain_out, num_round, verbose_eval = False, evals=evallist_out, early_stopping_rounds=10, evals_result=eval_results_out)\n",
    "\n",
    "    ypred_test_out = bst1.predict(dtest_out)\n",
    "    \n",
    "    ypred_train_out = bst1.predict(dtrain_out)\n",
    "    \n",
    "    mae_train_out = mean_absolute_error (y_train_out, ypred_train_out)\n",
    "    \n",
    "    mae_test_out = mean_absolute_error (y_test_out, ypred_test_out)\n",
    "    \n",
    "    min_eval_out = np.min(eval_results_out['eval'][eval_metric_name])\n",
    "\n",
    "    outer_results.loc[indexer_out,:] = [cv_ind_outer, max_depth_input_op, gamma_val_op, eta_val_op, mc_w_op, sub_op, reg_ind, min_eval_out, mae_test_out, mae_train_out]\n",
    "    indexer_out+=1\n",
    "    \n",
    "    print(f'outer results are \\n {outer_results}')\n",
    "    \n",
    "    fi_score = bst1.get_score (importance_type = 'cover')\n",
    "    \n",
    "    fi_comined.append(fi_score)\n",
    "\n",
    "    fi_mx.append(list(fi_score.values()))\n",
    "\n",
    "    fi_feat.append(list(fi_score.keys()))\n",
    "    \n",
    "    print(f'score values {fi_mx}')\n",
    "    \n",
    "    print(f'score keys {fi_feat}')\n",
    "     \n",
    "optimization_folds # Optimization Variables\n",
    "    \n",
    "min_folds_params = optimization_folds [np.where(optimization_folds == np.array(optimization_folds)[:,5].min())[0][0],:] #optimized parameters of the kfold cross validation\n",
    "\n",
    "fueatute_imo = DataFrame(fi_mx, columns = list(fi_score.keys())) #feature importance for the folds\n",
    "\n",
    "optimization_par  # the whole parameter variation dataframe\n",
    "\n",
    "print (f'omtimized values are {min_folds_params}')\n",
    "\n",
    "font = {'family' : 'arial',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 13}\n",
    "mpl.rc('font', **font)\n",
    "imp = xgb.plot_importance(bst, height=0.8, xlim=None, ylim=None, fmap='', importance_type='cover', max_num_features=None, grid=False, show_values=False, color = 'k')\n",
    "imp = imp.plot(color='k')\n",
    "#plt.title('Feature Importance (wieght)',weight='bold')\n",
    "plt.title(None)\n",
    "#plt.xlabel('F Score',weight='bold')\n",
    "plt.xlabel(None)\n",
    "plt.ylabel(None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2d167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_data = PPdata[['RACE', 'CCI_POA', 'SEX', 'AGE', 'TYPE_OF_ADMISSION', 'MEDICARE_STATUS_CODE']]\n",
    "\n",
    "y_data = PPdata['ICU']\n",
    "    \n",
    "#compute optimal params\n",
    "\n",
    "# fit final model with optimal params\n",
    "mlp_opt = SVR(C=10, kernel='rbf', degree=1, gamma='auto').fit(x_data,y_data)\n",
    "\n",
    "# begin feature importance eval\n",
    "feat_names = np.array([\"AGE\",\"SEX\",\"RACE\",\"CCI\",\"TOA\",\"OREC\"])\n",
    "scoring = ['r2', 'neg_mean_absolute_error', 'neg_mean_squared_error']\n",
    "r_multi = permutation_importance(mlp_opt,x_data,y_data,n_repeats=10,random_state=42,scoring=scoring)\n",
    "\n",
    "for metric in r_multi:\n",
    "    print(f\"{metric}\")\n",
    "    r = r_multi[metric]\n",
    "    \n",
    "    for i in r.importances_mean.argsort()[::-1]:\n",
    "        \n",
    "        if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "            print(f\"    {feat_names[i]:<8}\"\n",
    "            f\"{r.importances_mean[i]:.3f}\"\n",
    "            f\" +/- {r.importances_std[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670ec804",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = PPdata[[\"AGE\",\"SEX\",\"RACE\",\"CCI\",\"TYPE_OF_ADMISSION\",\"MEDICARE_STATUS_CODE\"]]\n",
    "\n",
    "r = r_multi['neg_mean_absolute_error']\n",
    "\n",
    "sorted_importances_idx = r.importances_mean.argsort()\n",
    "importances = pd.DataFrame(\n",
    "    r.importances[sorted_importances_idx].T,columns=X.columns[sorted_importances_idx],)\n",
    "\n",
    "test = importances.mean().sort_values(ascending=True)\n",
    "\n",
    "ax = test.plot.barh()\n",
    "#ax.set_title(\"Permutation Importances (test set)\",fontdict=titledict)\n",
    "ax.set_xlabel(\"Decrease in accuracy score\",fontdict= {'fontsize':20,'fontweight':'bold'})\n",
    "ax.set_yticklabels(test.index,size = 15,weight='bold')\n",
    "ax.set_xticklabels(ax.get_xticks(),size = 15,weight='bold')\n",
    "#ax.xaxis.set_major_formatter(FormatStrFormatter('%.2f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00217ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## XGBOOST grid search with repeated stratified kfold validation\n",
    "data = PPdata[['RACE', 'CCI', 'SEX', 'AGE', 'TYPE_OF_ADMISSION', 'MEDICARE_STATUS_CODE']]\n",
    "\n",
    "lable = PPdata['ICU']\n",
    "\n",
    "model = XGBRegressor()\n",
    "cv_inner= KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "space = dict()\n",
    "space['objective'] = ['reg:squarederror']\n",
    "space['max_depth'] = [3,4,5,6,7,8,9,10,11,12,13,14,15,16]\n",
    "space['min_child_weight'] = [1, 5, 10, 20]\n",
    "space['learning_rate'] = [0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.5]\n",
    "space['subsample'] = [0.5, 0.7, 0.9, 1]\n",
    "space['gamma'] = [0, 10, 50, 100]\n",
    "\n",
    "# Define Search\n",
    "search = GridSearchCV(model, space, scoring='neg_mean_absolute_error', n_jobs=-1, cv=cv_inner, verbose=0)\n",
    "# Execute Search\n",
    "search.fit(X_train, y_train)\n",
    "print(search.best_params_)\n",
    "\n",
    "# CV \n",
    "cv_outer = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "scores = cross_val_score(search, data, lable, scoring='neg_mean_absolute_error', cv=cv_outer, n_jobs=-1)\n",
    "\n",
    "print((scores.mean(), scores.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c49ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SVM grid search with repeated stratified kfold validation\n",
    "\n",
    "data = PPdata[['RACE', 'CCI', 'SEX', 'AGE', 'TYPE_OF_ADMISSION', 'MEDICARE_STATUS_CODE']]\n",
    "\n",
    "lable = PPdata['ICU']\n",
    "\n",
    "model = SVR()\n",
    "# define evaluation\n",
    "cv_inner= KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# define search space\n",
    "\n",
    "space = dict()\n",
    "space['kernel'] = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "space['degree'] = [1,2,3,5]\n",
    "space['C'] = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "space['gamma'] = ['scale', 'auto']\n",
    "\n",
    "# Define Search\n",
    "search = GridSearchCV(model, space, scoring='neg_mean_absolute_error', n_jobs=-1, cv=cv_inner, verbose=0)\n",
    "# Execute Search\n",
    "search.fit(X_train, y_train)\n",
    "print(search.best_params_) \n",
    "\n",
    "# CV\n",
    "cv_outer = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "scores = cross_val_score(search, data, lable, scoring='neg_mean_absolute_error', cv=cv_outer, n_jobs=-1)\n",
    "\n",
    "print((scores.mean(), scores.std()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
